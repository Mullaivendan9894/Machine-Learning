# Census Income Classification

## üìå Project Overview
This project aims to classify individuals based on their annual income using the **1994 U.S. Census dataset**. The goal is to predict whether an individual's income exceeds **$50,000 per year**, leveraging various **machine learning models** and **feature engineering techniques**.

## üìÇ Dataset Information
- **Source**: Extracted from the 1994 U.S. Census database.
- **Total Samples**: 48,842
- **Total Features**: 14 (excluding target variable)
- **Target Variable**: `income` (Binary classification: `<=50K` or `>50K`)

### üîπ Feature Types:
#### **Numerical Features**:
- `age`, `fnlwgt`, `educational-num`, `capital-gain`, `capital-loss`, `hours-per-week`

#### **Categorical Features**:
- `workclass`, `education`, `marital-status`, `occupation`, `relationship`, `race`, `gender`, `native-country`

## üöÄ Project Pipeline
### **1Ô∏è‚É£ Data Preprocessing**
‚úî Handling missing values (mode for categorical, median for numerical)
‚úî Removing duplicate rows
‚úî Handling outliers using Z-score method
‚úî Basic feature engineering:
   - Created `capital-net` (capital-gain - capital-loss)
   - Binned `age` into age groups
   - Simplified `native-country` into `US` vs. `Non-US`

### **2Ô∏è‚É£ Exploratory Data Analysis (EDA)**
‚úî Summary statistics for numerical and categorical variables
‚úî Data visualization: histograms, count plots, box plots
‚úî Hypothesis testing (Chi-square test, t-test) to analyze relationships
‚úî Class imbalance check

### **3Ô∏è‚É£ Feature Engineering & Encoding**
‚úî Dropped redundant features (`fnlwgt`)
‚úî Ordinal encoding for ordered categories (`education`, `age_group`)
‚úî Label encoding for categorical variables
‚úî Standardization of numerical features

### **4Ô∏è‚É£ Handling Class Imbalance**
‚úî Applied **SMOTE (Synthetic Minority Over-sampling Technique)** to balance the dataset

### **5Ô∏è‚É£ Feature Selection**
‚úî Used **Random Forest** & **Recursive Feature Elimination (RFE)** to select top features
‚úî Retained **10 most important features** for model training

### **6Ô∏è‚É£ Model Building & Evaluation**
Multiple machine learning models were trained and evaluated:
| Model | Accuracy | Precision | Recall |
|--------|----------|-----------|--------|
| **Logistic Regression** | 71.87% | 81.14% | 71.87% |
| **Decision Tree Classifier** | 80.35% | 82.99% | 80.35% |
| **Random Forest Classifier** | 81.48% | 84.09% | 81.48% |
| **Gradient Boosting Classifier** | 80.70% | 85.92% | 80.70% |
| **XGBoost Classifier** | **81.90%** | **85.88%** | **81.90%** |
| **XGB_RF Classifier** | 77.39% | 85.80% | 77.39% |

### **7Ô∏è‚É£ Hyperparameter Tuning**
‚úî **GridSearchCV** used to fine-tune the XGBoost model
‚úî Best parameters found:
   ```json
   {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}
   ```
‚úî **Final XGBoost Model Performance:**
   - **Accuracy:** 81.96%
   - **Precision:** 85.60%
   - **Recall:** 81.96%

## üìå Conclusion
- The **XGBoost Classifier** performed the best with **81.96% accuracy** after hyperparameter tuning.
- The project successfully tackled challenges like **class imbalance** and **feature selection**, leading to improved model performance.
- Future improvements:
  - Further optimize model performance (e.g., boosting techniques, deep learning)
  - Deploy the model using Flask/Streamlit
  - Experiment with additional feature engineering strategies


